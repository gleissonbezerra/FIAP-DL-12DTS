{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "hLTwLFAr51pA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_mj4oNn5pjh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurações"
      ],
      "metadata": {
        "id": "SIHOchoJa9j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('dark_background')\n",
        "plt.rcParams['figure.figsize'] = (8,6)\n",
        "plt.rcParams['lines.linewidth'] = 3\n",
        "plt.rcParams['font.size'] = 15"
      ],
      "metadata": {
        "id": "GjwuMfkla_fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "GT8rzbDigTQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc = [\"EU\", \"VOCÊ\", \"É\", \"SOU\", \"MUITO\", \"LEGAL\", \"DEMAIS\", \"INCRÍVEL\"]\n",
        "\n",
        "def encode(text):\n",
        "  a_text = text.split(\" \")\n",
        "  r = []\n",
        "  for i in a_text:\n",
        "    if i in voc:\n",
        "      r.append(voc.index(i))\n",
        "  return np.array(r)\n",
        "\n",
        "def probs(word):\n",
        "  r = np.zeros(len(voc))\n",
        "  i = voc.index(word)\n",
        "\n",
        "  if i > -1:\n",
        "    r[i] = 1.0\n",
        "\n",
        "  return r\n",
        "\n",
        "def decode(a_text):\n",
        "  return voc[np.argmax(a_text)]"
      ],
      "metadata": {
        "id": "anvPSqHfgWcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "9wHLmjR7VJi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([\n",
        "    encode(\"EU SOU MUITO\"),\n",
        "    encode(\"MUITO LEGAL EU\"),\n",
        "    encode(\"EU SOU LEGAL\"),\n",
        "    encode(\"VOCÊ É MUITO\"),\n",
        "    encode(\"VOCÊ É LEGAL\")\n",
        "    ])\n",
        "\n",
        "targets = np.array([\n",
        "    probs(\"LEGAL\"),\n",
        "    probs(\"SOU\"),\n",
        "    probs(\"DEMAIS\"),\n",
        "    probs(\"LEGAL\"),\n",
        "    probs(\"DEMAIS\")\n",
        "    ])\n",
        "\n",
        "print(f\"Inputs: \\n{inputs}\")\n",
        "print(f\"Targets: \\n{targets}\")"
      ],
      "metadata": {
        "id": "WeQ5Zn2uNug8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura (INCORRETA)"
      ],
      "metadata": {
        "id": "0soM_UorWIOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Inicialização dos pesos e biases\n",
        "        self.weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))\n",
        "        self.weights_hidden_hidden = np.random.uniform(size=(hidden_size, hidden_size))\n",
        "        self.biases_hidden = np.zeros(hidden_size)\n",
        "\n",
        "        self.weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))\n",
        "        self.biases_output = np.zeros(output_size)\n",
        "\n",
        "        # Estado oculto\n",
        "        self.hidden_state = np.zeros(hidden_size)\n",
        "\n",
        "    # def sigmoid(self, x):\n",
        "    #     return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # def sigmoid_derivative(self, x):\n",
        "    #     return x * (1 - x)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def tanh_derivative(self, x):\n",
        "        return 1.0 - np.tanh(x)**2\n",
        "\n",
        "    def softmax(self, x):\n",
        "      exp_x = np.exp(x)\n",
        "      sum_exp_x = np.sum(exp_x, axis=-1, keepdims=True)\n",
        "      return exp_x / sum_exp_x\n",
        "\n",
        "\n",
        "    def train(self, inputs, targets, epochs, learning_rate):\n",
        "        loss_history = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "\n",
        "            for i in range(len(inputs)):\n",
        "                # Forward pass\n",
        "                input_layer = inputs[i]\n",
        "                hidden_layer_input = np.dot(input_layer, self.weights_input_hidden) + np.dot(self.hidden_state, self.weights_hidden_hidden) + self.biases_hidden\n",
        "                hidden_layer_output = self.tanh(hidden_layer_input)\n",
        "                #hidden_layer_output = self.sigmoid(hidden_layer_input)\n",
        "\n",
        "\n",
        "                output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_output) + self.biases_output\n",
        "                predicted_output = output_layer_input\n",
        "\n",
        "                # Calcula o erro\n",
        "                error = targets[i] - predicted_output\n",
        "                total_loss += np.sum(error ** 2)\n",
        "\n",
        "                # Backpropagation\n",
        "                output_delta = error\n",
        "                hidden_delta = output_delta.dot(self.weights_hidden_output.T) * self.tanh_derivative(hidden_layer_output)\n",
        "                #hidden_delta = output_delta.dot(self.weights_hidden_output.T) * self.sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\n",
        "                # Atualiza os pesos e biases\n",
        "                self.weights_hidden_output += hidden_layer_output.reshape(-1, 1) * output_delta * learning_rate\n",
        "                self.biases_output += output_delta * learning_rate\n",
        "\n",
        "                self.weights_input_hidden += input_layer.reshape(-1, 1) * hidden_delta * learning_rate\n",
        "                self.weights_hidden_hidden += np.outer(self.hidden_state, hidden_delta) * learning_rate\n",
        "                self.biases_hidden += hidden_delta * learning_rate\n",
        "\n",
        "                # Atualiza o estado oculto\n",
        "                self.hidden_state = hidden_layer_output\n",
        "\n",
        "            # Calcula o erro médio quadrático médio para a época\n",
        "            avg_loss = total_loss / len(inputs)\n",
        "            loss_history.append(avg_loss)\n",
        "\n",
        "            # Exibe o erro médio quadrático a cada época\n",
        "            print(f\"Época {epoch + 1}/{epochs}, Erro Médio Quadrático: {avg_loss}\")\n",
        "\n",
        "        return loss_history\n",
        "\n",
        "    def predict(self, initial_sequence):\n",
        "        current_input = np.array(initial_sequence)\n",
        "        hidden_layer_input = np.dot(current_input, self.weights_input_hidden) + np.dot(self.hidden_state, self.weights_hidden_hidden) + self.biases_hidden\n",
        "        hidden_layer_output = self.tanh(hidden_layer_input)\n",
        "        #hidden_layer_output = self.sigmoid(hidden_layer_input)\n",
        "\n",
        "        output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_output) + self.biases_output\n",
        "        predicted_output = output_layer_input\n",
        "\n",
        "        # Atualiza o estado oculto\n",
        "        self.hidden_state = hidden_layer_output\n",
        "\n",
        "        return predicted_output"
      ],
      "metadata": {
        "id": "UQOSlQmp0ZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "LKNV4Xg_WsRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros\n",
        "epochs = 8000\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Cria e treina a RRN\n",
        "rnn = SimpleRNN(input_size=len(inputs[0]), hidden_size=10, output_size=len(targets[0]))\n",
        "losses = rnn.train(inputs, targets, epochs, learning_rate)\n"
      ],
      "metadata": {
        "id": "njJJ2di9Wtlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_epochs = np.arange(0, epochs, 1)\n",
        "\n",
        "plt.plot(data_epochs, losses, color=\"yellow\", lw=5, label = 'MSE')\n",
        "\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Bu6lcAXmYtwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste"
      ],
      "metadata": {
        "id": "XL0IolT6W7Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa a previsão com uma nova sequência\n",
        "#test_sequence = [1, 0, 1]\n",
        "\n",
        "text = \"EU SOU MUITO\" #Valor conhecido\n",
        "# text = \"VOCÊ É INCRÍVEL\" #valor desconhecido\n",
        "# text = \"SOU MUITO INCRÍVEL\" #valor desconhecido meio provável\n",
        "# text = \"VOCÊ É EU\" #valor desconhecido improvável\n",
        "# text = \"EU SOU É\" #valor desconhecido improvável\n",
        "\n",
        "test_sequence = encode(text)\n",
        "predicted_output = rnn.predict(test_sequence)\n",
        "\n",
        "print(f\"Vocabulário: {voc}\")\n",
        "print()\n",
        "print(f\"Frases conhecidas:\\n\")\n",
        "\n",
        "for i in range(len(inputs)):\n",
        "    s = \"\"\n",
        "    for j in inputs[i]:\n",
        "      s += voc[j] +\" \"\n",
        "    print(f\"{s}{decode(targets[i])}\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Sequência de entrada: {test_sequence}\")\n",
        "print(f\"Sequência prevista: {predicted_output}\")\n",
        "print()\n",
        "\n",
        "print(f\"Texto de entrada: {text} ...\")\n",
        "print(f\"Texto de saída: {text} {decode(predicted_output)}. ({np.max(predicted_output)})\")\n"
      ],
      "metadata": {
        "id": "BhxLeoGgW8kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questões\n",
        "\n",
        "1. Corriga o código para gerar a distribuição de probabilidades das palavras do vocabulário.\n",
        "2. Execute os diversos casos de teste a acima e observe os resultados.\n",
        "3. Modifique para função sigmoid e derivada da sigmoid o treinamento. Os resultados foram piores? Melhores?"
      ],
      "metadata": {
        "id": "K0AbMZLXwUP2"
      }
    }
  ]
}